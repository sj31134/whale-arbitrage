#!/usr/bin/env python3
"""
BSC Hybrid Collector

BSC ê±°ë˜ ìˆ˜ì§‘ì„ ìœ„í•œ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ
1. APIë¡œ ëª¨ë“  ê±°ë˜ ìˆ˜ì§‘ (ë¹ ë¥´ê³  ì •í™•)
2. ê³ ì•¡ ê±°ë˜ í•„í„°ë§
3. ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ ë³´ì™„ (Method, Label ë“±)
4. whale_transactions í…Œì´ë¸”ì— ì €ì¥
"""

import os
import sys
import json
import time
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from scripts.collectors.bsc_api_collector import (
    get_bsc_addresses_from_supabase,
    collect_all_bsc_transactions,
    is_high_value_transaction,
    save_to_whale_transactions,
    get_supabase_client
)

from scripts.collectors.bsc_web_scraper import (
    scrape_multiple_transactions
)

# ì„¤ì •
CHECKPOINT_FILE = PROJECT_ROOT / "checkpoints" / "bsc_hybrid_checkpoint.json"
DEFAULT_MIN_BNB = 100  # BNB ê¸°ì¤€
DEFAULT_MIN_USD = 50000  # USD ê¸°ì¤€
WEB_SCRAPING_DELAY = 2  # ì´ˆ


def load_checkpoint() -> Dict:
    """
    ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ë¡œë“œ
    
    Returns:
    --------
    Dict : ì²´í¬í¬ì¸íŠ¸ ë°ì´í„°
    """
    if not CHECKPOINT_FILE.exists():
        return {
            'last_run': None,
            'processed_addresses': [],
            'high_value_txs_scraped': [],
            'total_collected': 0,
            'total_scraped': 0
        }
    
    try:
        with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {
            'last_run': None,
            'processed_addresses': [],
            'high_value_txs_scraped': [],
            'total_collected': 0,
            'total_scraped': 0
        }


def save_checkpoint(checkpoint: Dict):
    """
    ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    
    Parameters:
    -----------
    checkpoint : Dict
        ì €ì¥í•  ì²´í¬í¬ì¸íŠ¸ ë°ì´í„°
    """
    try:
        # ë””ë ‰í† ë¦¬ ìƒì„±
        CHECKPOINT_FILE.parent.mkdir(parents=True, exist_ok=True)
        
        # í˜„ì¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        checkpoint['last_run'] = datetime.now().isoformat()
        
        with open(CHECKPOINT_FILE, 'w', encoding='utf-8') as f:
            json.dump(checkpoint, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {CHECKPOINT_FILE}")
    
    except Exception as e:
        print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")


def save_backup_csv(transactions: List[Dict], filename: str):
    """
    ë¡œì»¬ CSV ë°±ì—… ì €ì¥
    
    Parameters:
    -----------
    transactions : List[Dict]
        ê±°ë˜ ë¦¬ìŠ¤íŠ¸
    filename : str
        íŒŒì¼ëª…
    """
    import csv
    
    try:
        backup_dir = PROJECT_ROOT / "data" / "backups"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        filepath = backup_dir / filename
        
        if not transactions:
            return
        
        fieldnames = list(transactions[0].keys())
        
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for tx in transactions:
                row = tx.copy()
                # datetimeì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                if isinstance(row.get('block_timestamp'), datetime):
                    row['block_timestamp'] = row['block_timestamp'].isoformat()
                writer.writerow(row)
        
        print(f"ğŸ’¾ ë°±ì—… ì €ì¥: {filepath}")
    
    except Exception as e:
        print(f"âš ï¸ ë°±ì—… ì €ì¥ ì‹¤íŒ¨: {e}")


def filter_high_value_transactions(
    transactions: List[Dict],
    min_bnb: float = DEFAULT_MIN_BNB,
    min_usd: Optional[float] = DEFAULT_MIN_USD
) -> List[Dict]:
    """
    ê³ ì•¡ ê±°ë˜ í•„í„°ë§
    
    Parameters:
    -----------
    transactions : List[Dict]
        ì „ì²´ ê±°ë˜ ë¦¬ìŠ¤íŠ¸
    min_bnb : float
        ìµœì†Œ BNB ê¸ˆì•¡
    min_usd : Optional[float]
        ìµœì†Œ USD ê¸ˆì•¡
    
    Returns:
    --------
    List[Dict] : ê³ ì•¡ ê±°ë˜ ë¦¬ìŠ¤íŠ¸
    """
    high_value_txs = []
    
    for tx in transactions:
        amount = tx.get('amount', 0)
        coin_symbol = tx.get('coin_symbol', 'BNB')
        
        # BNB ê¸°ì¤€
        if coin_symbol == 'BNB' and amount >= min_bnb:
            high_value_txs.append(tx)
            continue
        
        # USD ê¸°ì¤€ (ìˆëŠ” ê²½ìš°)
        if min_usd:
            amount_usd = tx.get('amount_usd')
            if amount_usd and amount_usd >= min_usd:
                high_value_txs.append(tx)
    
    return high_value_txs


def run_hybrid_collection(
    addresses: Optional[List[str]] = None,
    skip_scraping: bool = False,
    min_bnb: float = DEFAULT_MIN_BNB,
    min_usd: float = DEFAULT_MIN_USD,
    save_to_db: bool = True,
    web_scraping_delay: float = WEB_SCRAPING_DELAY
) -> Dict:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ìˆ˜ì§‘ ì‹¤í–‰
    
    Parameters:
    -----------
    addresses : Optional[List[str]]
        ìˆ˜ì§‘í•  ì£¼ì†Œ ë¦¬ìŠ¤íŠ¸ (Noneì¼ ê²½ìš° Supabaseì—ì„œ ì¡°íšŒ)
    skip_scraping : bool
        ì›¹ ìŠ¤í¬ë˜í•‘ ê±´ë„ˆë›°ê¸°
    min_bnb : float
        ì›¹ ìŠ¤í¬ë˜í•‘ ëŒ€ìƒ ìµœì†Œ BNB ê¸ˆì•¡
    min_usd : float
        ì›¹ ìŠ¤í¬ë˜í•‘ ëŒ€ìƒ ìµœì†Œ USD ê¸ˆì•¡
    save_to_db : bool
        ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì—¬ë¶€
    web_scraping_delay : float
        ì›¹ ìŠ¤í¬ë˜í•‘ ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„
    
    Returns:
    --------
    Dict : ì‹¤í–‰ ê²°ê³¼ í†µê³„
    """
    start_time = datetime.now()
    
    print(f"\n{'='*80}")
    print(f"BSC Hybrid Collection System")
    print(f"{'='*80}")
    print(f"ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ì„¤ì •:")
    print(f"  - ì›¹ ìŠ¤í¬ë˜í•‘: {'ë¹„í™œì„±í™”' if skip_scraping else 'í™œì„±í™”'}")
    print(f"  - ìµœì†Œ BNB: {min_bnb}")
    print(f"  - ìµœì†Œ USD: ${min_usd:,}")
    print(f"  - DB ì €ì¥: {'í™œì„±í™”' if save_to_db else 'ë¹„í™œì„±í™”'}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = load_checkpoint()
    
    # Step 1: APIë¡œ ê±°ë˜ ìˆ˜ì§‘
    print(f"\n{'='*80}")
    print(f"Step 1: APIë¥¼ í†µí•œ ê±°ë˜ ìˆ˜ì§‘")
    print(f"{'='*80}")
    
    all_transactions = collect_all_bsc_transactions(addresses)
    
    if not all_transactions:
        print("âš ï¸ ìˆ˜ì§‘ëœ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {
            'total_collected': 0,
            'high_value_count': 0,
            'scraped_count': 0,
            'saved_count': 0,
            'duration_seconds': 0
        }
    
    # ë°±ì—… ì €ì¥
    backup_filename = f"bsc_transactions_api_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    save_backup_csv(all_transactions, backup_filename)
    
    # Step 2: ê³ ì•¡ ê±°ë˜ í•„í„°ë§
    print(f"\n{'='*80}")
    print(f"Step 2: ê³ ì•¡ ê±°ë˜ í•„í„°ë§")
    print(f"{'='*80}")
    
    high_value_txs = filter_high_value_transactions(
        all_transactions,
        min_bnb=min_bnb,
        min_usd=min_usd
    )
    
    print(f"ì „ì²´ ê±°ë˜: {len(all_transactions)}ê±´")
    print(f"ê³ ì•¡ ê±°ë˜: {len(high_value_txs)}ê±´ ({len(high_value_txs)/len(all_transactions)*100:.1f}%)")
    
    # Step 3: ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ ë³´ì™„
    scraped_count = 0
    
    if not skip_scraping and high_value_txs:
        print(f"\n{'='*80}")
        print(f"Step 3: ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ ë³´ì™„")
        print(f"{'='*80}")
        print(f"ëŒ€ìƒ: {len(high_value_txs)}ê±´")
        print(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {len(high_value_txs) * web_scraping_delay / 60:.1f}ë¶„")
        
        # ì´ë¯¸ ìŠ¤í¬ë˜í•‘í•œ ê±°ë˜ ì œì™¸
        already_scraped = set(checkpoint.get('high_value_txs_scraped', []))
        txs_to_scrape = [
            tx for tx in high_value_txs 
            if tx.get('tx_hash') not in already_scraped
        ]
        
        if txs_to_scrape:
            print(f"ìƒˆë¡œ ìŠ¤í¬ë˜í•‘í•  ê±°ë˜: {len(txs_to_scrape)}ê±´")
            
            enriched_txs = scrape_multiple_transactions(
                txs_to_scrape,
                delay=web_scraping_delay
            )
            
            # ì›ë³¸ ê±°ë˜ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            enriched_tx_map = {tx['tx_hash']: tx for tx in enriched_txs}
            
            for i, tx in enumerate(all_transactions):
                tx_hash = tx.get('tx_hash')
                if tx_hash in enriched_tx_map:
                    all_transactions[i] = enriched_tx_map[tx_hash]
            
            # ì²´í¬í¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
            checkpoint['high_value_txs_scraped'].extend([tx['tx_hash'] for tx in enriched_txs])
            scraped_count = len(enriched_txs)
        else:
            print(f"âœ“ ëª¨ë“  ê³ ì•¡ ê±°ë˜ê°€ ì´ë¯¸ ìŠ¤í¬ë˜í•‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ë°±ì—… ì €ì¥ (ìŠ¤í¬ë˜í•‘ í›„)
        backup_filename = f"bsc_transactions_enriched_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        save_backup_csv(all_transactions, backup_filename)
    
    else:
        print(f"\nâ­ï¸  Step 3: ì›¹ ìŠ¤í¬ë˜í•‘ ê±´ë„ˆë›°ê¸°")
    
    # Step 4: whale_transactions í…Œì´ë¸”ì— ì €ì¥
    saved_count = 0
    
    if save_to_db:
        print(f"\n{'='*80}")
        print(f"Step 4: whale_transactions í…Œì´ë¸”ì— ì €ì¥")
        print(f"{'='*80}")
        
        saved_count = save_to_whale_transactions(all_transactions)
        
        # ì²´í¬í¬ì¸íŠ¸ ì—…ë°ì´íŠ¸
        checkpoint['total_collected'] += len(all_transactions)
        checkpoint['total_scraped'] += scraped_count
    
    else:
        print(f"\nâ­ï¸  Step 4: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê±´ë„ˆë›°ê¸°")
    
    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    save_checkpoint(checkpoint)
    
    # ê²°ê³¼ ìš”ì•½
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    print(f"\n{'='*80}")
    print(f"ì‹¤í–‰ ì™„ë£Œ")
    print(f"{'='*80}")
    print(f"ì¢…ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ì†Œìš” ì‹œê°„: {duration/60:.1f}ë¶„ ({duration:.0f}ì´ˆ)")
    print(f"\nğŸ“Š í†µê³„:")
    print(f"  - ì „ì²´ ê±°ë˜ ìˆ˜ì§‘: {len(all_transactions)}ê±´")
    print(f"  - ê³ ì•¡ ê±°ë˜: {len(high_value_txs)}ê±´")
    print(f"  - ì›¹ ìŠ¤í¬ë˜í•‘: {scraped_count}ê±´")
    print(f"  - DB ì €ì¥: {saved_count}ê±´")
    
    return {
        'total_collected': len(all_transactions),
        'high_value_count': len(high_value_txs),
        'scraped_count': scraped_count,
        'saved_count': saved_count,
        'duration_seconds': duration
    }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='BSC Hybrid Collection System',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‹¤í–‰ (API + ì›¹ ìŠ¤í¬ë˜í•‘ + DB ì €ì¥)
  python bsc_hybrid_collector.py
  
  # APIë§Œ ì‹¤í–‰ (ì›¹ ìŠ¤í¬ë˜í•‘ ê±´ë„ˆë›°ê¸°)
  python bsc_hybrid_collector.py --skip-scraping
  
  # ê³ ì•¡ ê±°ë˜ ê¸°ì¤€ ë³€ê²½
  python bsc_hybrid_collector.py --min-bnb 1000 --min-usd 500000
  
  # DB ì €ì¥ ì—†ì´ ìˆ˜ì§‘ë§Œ
  python bsc_hybrid_collector.py --no-save
  
  # ì›¹ ìŠ¤í¬ë˜í•‘ ì†ë„ ì¡°ì ˆ
  python bsc_hybrid_collector.py --scraping-delay 5
        """
    )
    
    parser.add_argument(
        '--skip-scraping',
        action='store_true',
        help='ì›¹ ìŠ¤í¬ë˜í•‘ ê±´ë„ˆë›°ê¸° (APIë§Œ ì‚¬ìš©)'
    )
    
    parser.add_argument(
        '--min-bnb',
        type=float,
        default=DEFAULT_MIN_BNB,
        help=f'ì›¹ ìŠ¤í¬ë˜í•‘ ëŒ€ìƒ ìµœì†Œ BNB ê¸ˆì•¡ (ê¸°ë³¸ê°’: {DEFAULT_MIN_BNB})'
    )
    
    parser.add_argument(
        '--min-usd',
        type=float,
        default=DEFAULT_MIN_USD,
        help=f'ì›¹ ìŠ¤í¬ë˜í•‘ ëŒ€ìƒ ìµœì†Œ USD ê¸ˆì•¡ (ê¸°ë³¸ê°’: {DEFAULT_MIN_USD})'
    )
    
    parser.add_argument(
        '--no-save',
        action='store_true',
        help='ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê±´ë„ˆë›°ê¸° (ë°±ì—… CSVë§Œ ì €ì¥)'
    )
    
    parser.add_argument(
        '--scraping-delay',
        type=float,
        default=WEB_SCRAPING_DELAY,
        help=f'ì›¹ ìŠ¤í¬ë˜í•‘ ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„(ì´ˆ) (ê¸°ë³¸ê°’: {WEB_SCRAPING_DELAY})'
    )
    
    parser.add_argument(
        '--test',
        action='store_true',
        help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì²« 3ê°œ ì£¼ì†Œë§Œ)'
    )
    
    args = parser.parse_args()
    
    try:
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        addresses = None
        if args.test:
            print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²˜ìŒ 3ê°œ ì£¼ì†Œë§Œ ì²˜ë¦¬")
            addresses = get_bsc_addresses_from_supabase()[:3]
        
        # ì‹¤í–‰
        result = run_hybrid_collection(
            addresses=addresses,
            skip_scraping=args.skip_scraping,
            min_bnb=args.min_bnb,
            min_usd=args.min_usd,
            save_to_db=not args.no_save,
            web_scraping_delay=args.scraping_delay
        )
        
        # ì„±ê³µ
        print(f"\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        return 0
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())




