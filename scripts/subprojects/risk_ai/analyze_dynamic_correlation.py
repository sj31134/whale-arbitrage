#!/usr/bin/env python3
"""
ë™ì  ë³€ìˆ˜ì™€ ê°€ê²© ë³€í™” ê°„ ìƒê´€ê´€ê³„ ë¶„ì„

ì¢…ì†ë³€ìˆ˜:
- price_change_1d: 1ì¼ í›„ ê°€ê²© ë³€í™”ìœ¨
- price_change_7d: 7ì¼ í›„ ê°€ê²© ë³€í™”ìœ¨
- volatility_change_1d: 1ì¼ í›„ ë³€ë™ì„± ë³€í™”ìœ¨
- price_direction_1d: 1ì¼ í›„ ê°€ê²© ë°©í–¥ (ìƒìŠ¹/í•˜ë½, binary)

ë…ë¦½ë³€ìˆ˜ (ë™ì  ë³€ìˆ˜):
- volatility_delta, volatility_accel, volatility_slope
- oi_delta, oi_accel, oi_slope
- funding_delta, funding_accel
- taker_ratio_delta, net_flow_delta
- ê¸°íƒ€ ëª¨ë“  ë™ì  ë³€ìˆ˜
"""

import os
import sys
import sqlite3
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from scipy import stats

# FDR ë³´ì • (ì„ íƒì )
try:
    from statsmodels.stats.multitest import multipletests
    HAS_STATSMODELS = True
except ImportError:
    HAS_STATSMODELS = False

ROOT = Path(__file__).resolve().parent.parents[2]
sys.path.insert(0, str(ROOT / "scripts" / "subprojects" / "risk_ai"))

from feature_engineering import FeatureEngineer

DB_PATH = ROOT / "data" / "project.db"
OUTPUT_DIR = ROOT / "data" / "analysis"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def load_price_data(coin: str = "BTC", start_date: str = "2022-01-01") -> pd.DataFrame:
    """ê°€ê²© ë°ì´í„° ë¡œë“œ"""
    conn = sqlite3.connect(DB_PATH)
    
    symbol = f"{coin}USDT"
    
    # binance_spot_dailyì—ì„œ ê°€ê²© ë°ì´í„° ë¡œë“œ
    query = f"""
    SELECT 
        date,
        close as price
    FROM binance_spot_daily
    WHERE symbol = '{symbol}'
    AND date >= '{start_date}'
    ORDER BY date
    """
    
    df = pd.read_sql(query, conn)
    conn.close()
    
    if len(df) == 0:
        return pd.DataFrame()
    
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values('date').reset_index(drop=True)
    
    return df


def calculate_target_variables(price_df: pd.DataFrame) -> pd.DataFrame:
    """ì¢…ì†ë³€ìˆ˜ ê³„ì‚°"""
    df = price_df.copy()
    
    # ê°€ê²© ë³€í™”ìœ¨
    df['price_change_1d'] = df['price'].pct_change(1).shift(-1)  # ë‹¤ìŒë‚  ë³€í™”ìœ¨
    df['price_change_7d'] = df['price'].pct_change(7).shift(-7)  # 7ì¼ í›„ ë³€í™”ìœ¨
    
    # ë³€ë™ì„± (20ì¼ ë¡¤ë§ í‘œì¤€í¸ì°¨)
    df['volatility'] = df['price'].pct_change().rolling(20).std()
    df['volatility_change_1d'] = df['volatility'].diff(1).shift(-1)  # ë‹¤ìŒë‚  ë³€ë™ì„± ë³€í™”
    
    # ê°€ê²© ë°©í–¥ (1ì¼ í›„ ìƒìŠ¹=1, í•˜ë½=0)
    df['price_direction_1d'] = (df['price_change_1d'] > 0).astype(int)
    
    return df


def calculate_correlations(
    dynamic_df: pd.DataFrame,
    target_df: pd.DataFrame,
    lags: list = [0, 1, 2, 3, 7]
) -> pd.DataFrame:
    """ìƒê´€ê´€ê³„ ê³„ì‚°"""
    # ë‚ ì§œ ê¸°ì¤€ ë³‘í•©
    merged = pd.merge(
        dynamic_df[['date'] + [col for col in dynamic_df.columns if any(x in col for x in ['delta', 'accel', 'slope', 'momentum', 'stability'])]],
        target_df[['date', 'price_change_1d', 'price_change_7d', 'volatility_change_1d', 'price_direction_1d']],
        on='date',
        how='inner'
    )
    
    results = []
    
    # ë™ì  ë³€ìˆ˜ í•„í„°ë§
    dynamic_cols = [col for col in merged.columns if any(x in col for x in ['delta', 'accel', 'slope', 'momentum', 'stability'])]
    target_cols = ['price_change_1d', 'price_change_7d', 'volatility_change_1d', 'price_direction_1d']
    
    for var in dynamic_cols:
        for target in target_cols:
            for lag in lags:
                if lag == 0:
                    x = merged[var]
                    y = merged[target]
                else:
                    x = merged[var].shift(lag)
                    y = merged[target]
                
                # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì‚¬ìš©
                valid_mask = ~(x.isna() | y.isna())
                x_valid = x[valid_mask]
                y_valid = y[valid_mask]
                
                if len(x_valid) < 30:  # ìµœì†Œ 30ê°œ ìƒ˜í”Œ í•„ìš”
                    continue
                
                # Pearson ìƒê´€ê³„ìˆ˜
                pearson_r, pearson_p = stats.pearsonr(x_valid, y_valid)
                
                # Spearman ìƒê´€ê³„ìˆ˜
                spearman_r, spearman_p = stats.spearmanr(x_valid, y_valid)
                
                results.append({
                    'variable': var,
                    'target': target,
                    'lag': lag,
                    'pearson_correlation': pearson_r,
                    'pearson_pvalue': pearson_p,
                    'spearman_correlation': spearman_r,
                    'spearman_pvalue': spearman_p,
                    'sample_size': len(x_valid)
                })
    
    return pd.DataFrame(results)


def apply_fdr_correction(results_df: pd.DataFrame) -> pd.DataFrame:
    """False Discovery Rate (FDR) ë³´ì •"""
    df = results_df.copy()
    
    if not HAS_STATSMODELS:
        print("   âš ï¸ statsmodelsê°€ ì—†ì–´ FDR ë³´ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return df
    
    # p-valueê°€ ìœ íš¨í•œ í–‰ë§Œ í•„í„°ë§
    valid_mask = df['pearson_pvalue'].notna()
    
    if valid_mask.sum() == 0:
        return df
    
    # FDR ë³´ì • (Benjamini-Hochberg)
    pvalues = df.loc[valid_mask, 'pearson_pvalue'].values
    _, pvalues_corrected, _, _ = multipletests(pvalues, method='fdr_bh')
    
    df.loc[valid_mask, 'pearson_pvalue_fdr'] = pvalues_corrected
    
    # Spearmanë„ ë™ì¼í•˜ê²Œ
    pvalues_spearman = df.loc[valid_mask, 'spearman_pvalue'].values
    _, pvalues_spearman_corrected, _, _ = multipletests(pvalues_spearman, method='fdr_bh')
    
    df.loc[valid_mask, 'spearman_pvalue_fdr'] = pvalues_spearman_corrected
    
    return df


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ë™ì  ë³€ìˆ˜ ìƒê´€ê´€ê³„ ë¶„ì„")
    parser.add_argument("--coin", type=str, default="BTC", choices=["BTC", "ETH"])
    parser.add_argument("--start-date", type=str, default="2022-01-01")
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ“Š ë™ì  ë³€ìˆ˜ ìƒê´€ê´€ê³„ ë¶„ì„")
    print("=" * 80)
    print(f"ì½”ì¸: {args.coin}")
    print(f"ì‹œì‘ì¼: {args.start_date}")
    print()
    
    # 1. ê°€ê²© ë°ì´í„° ë¡œë“œ
    print("[1/4] ê°€ê²© ë°ì´í„° ë¡œë“œ ì¤‘...")
    price_df = load_price_data(args.coin, args.start_date)
    
    if price_df.empty:
        print("âŒ ê°€ê²© ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"   âœ… {len(price_df)}ê±´ ë¡œë“œ ({price_df['date'].min()} ~ {price_df['date'].max()})")
    
    # 2. ì¢…ì†ë³€ìˆ˜ ê³„ì‚°
    print("\n[2/4] ì¢…ì†ë³€ìˆ˜ ê³„ì‚° ì¤‘...")
    target_df = calculate_target_variables(price_df)
    print(f"   âœ… ì¢…ì†ë³€ìˆ˜ ê³„ì‚° ì™„ë£Œ")
    
    # 3. ë™ì  ë³€ìˆ˜ í¬í•¨ í”¼ì²˜ ìƒì„±
    print("\n[3/4] ë™ì  ë³€ìˆ˜ í¬í•¨ í”¼ì²˜ ìƒì„± ì¤‘...")
    fe = FeatureEngineer()
    raw_df = fe.load_raw_data(args.start_date, coin=args.coin)
    
    if raw_df.empty:
        print("âŒ ì›ë³¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    dynamic_df, features = fe.create_features(raw_df, include_dynamic=True)
    print(f"   âœ… {len(features)}ê°œ í”¼ì²˜ ìƒì„± (ë™ì  ë³€ìˆ˜ í¬í•¨)")
    
    # 4. ìƒê´€ê´€ê³„ ê³„ì‚°
    print("\n[4/4] ìƒê´€ê´€ê³„ ê³„ì‚° ì¤‘...")
    results_df = calculate_correlations(dynamic_df, target_df)
    
    if results_df.empty:
        print("âŒ ìƒê´€ê´€ê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # FDR ë³´ì •
    results_df = apply_fdr_correction(results_df)
    
    # ìœ ì˜ë¯¸í•œ ê²°ê³¼ë§Œ í•„í„°ë§ (p < 0.05)
    significant = results_df[
        (results_df['pearson_pvalue'] < 0.05) | 
        (results_df.get('pearson_pvalue_fdr', 1) < 0.05)
    ]
    
    print(f"   âœ… ì´ {len(results_df)}ê°œ ì¡°í•© ë¶„ì„")
    print(f"   âœ… ìœ ì˜ë¯¸í•œ ìƒê´€ê´€ê³„: {len(significant)}ê°œ (p < 0.05)")
    
    # 5. ê²°ê³¼ ì €ì¥
    output_file = OUTPUT_DIR / f"dynamic_correlation_{args.coin}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    results_df.to_csv(output_file, index=False)
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    
    # 6. ìš”ì•½ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“Š ìƒìœ„ 10ê°œ ìœ ì˜ë¯¸í•œ ìƒê´€ê´€ê³„")
    print("=" * 80)
    
    top10 = significant.nlargest(10, 'pearson_correlation', keep='all')
    if len(top10) > 0:
        print(top10[['variable', 'target', 'lag', 'pearson_correlation', 'pearson_pvalue', 'sample_size']].to_string())
    else:
        print("ìœ ì˜ë¯¸í•œ ìƒê´€ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print("\n" + "=" * 80)
    print("âœ… ë¶„ì„ ì™„ë£Œ")
    print("=" * 80)


if __name__ == "__main__":
    main()

