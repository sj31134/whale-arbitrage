#!/usr/bin/env python3
"""
Project 3: Risk AI Model Training with Time Series Cross-Validation & Hyperparameter Tuning
"""

import pandas as pd
import numpy as np
from pathlib import Path
from feature_engineering import FeatureEngineer
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_recall_curve
from sklearn.model_selection import TimeSeriesSplit

# Optuna import ì²´í¬
try:
    import optuna
    from optuna.integration import LightGBMPruningCallback
    OPTUNA_AVAILABLE = True
except (ImportError, ModuleNotFoundError) as e:
    OPTUNA_AVAILABLE = False

ROOT = Path(__file__).resolve().parents[3]


def time_series_cross_validation(X, y, n_splits=5):
    """Time Series Cross-Validation ìˆ˜í–‰"""
    tscv = TimeSeriesSplit(n_splits=n_splits)
    cv_scores = []
    
    print(f"\nğŸ“Š Time Series Cross-Validation ({n_splits}-fold)")
    print("=" * 80)
    
    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):
        X_train_fold = X.iloc[train_idx]
        y_train_fold = y.iloc[train_idx]
        X_val_fold = X.iloc[val_idx]
        y_val_fold = y.iloc[val_idx]
        
        print(f"\nFold {fold}/{n_splits}:")
        print(f"  Train: {len(X_train_fold)}ê±´ ({X_train_fold.index[0]} ~ {X_train_fold.index[-1]})")
        print(f"  Val:   {len(X_val_fold)}ê±´ ({X_val_fold.index[0]} ~ {X_val_fold.index[-1]})")
        
        # ëª¨ë¸ í•™ìŠµ
        model = LGBMClassifier(
            n_estimators=200,
            learning_rate=0.05,
            max_depth=5,
            random_state=42,
            class_weight='balanced',
            verbosity=-1
        )
        
        model.fit(X_train_fold, y_train_fold)
        
        # í‰ê°€
        y_pred_proba = model.predict_proba(X_val_fold)[:, 1]
        
        try:
            auc = roc_auc_score(y_val_fold, y_pred_proba)
            cv_scores.append(auc)
            print(f"  AUC-ROC: {auc:.4f}")
        except ValueError as e:
            print(f"  âš ï¸ AUC-ROC ê³„ì‚° ë¶ˆê°€: {e}")
            cv_scores.append(0.0)
    
    print(f"\nğŸ“ˆ Cross-Validation ê²°ê³¼:")
    print(f"  í‰ê·  AUC-ROC: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})")
    print(f"  ìµœì†Œ: {np.min(cv_scores):.4f}")
    print(f"  ìµœëŒ€: {np.max(cv_scores):.4f}")
    
    return cv_scores


def objective(trial, X_train, y_train, X_val, y_val):
    """Optuna objective function"""
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 500),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        'class_weight': 'balanced',
        'random_state': 42,
        'verbosity': -1
    }
    
    model = LGBMClassifier(**params)
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        callbacks=[LightGBMPruningCallback(trial, 'binary_logloss')]
    )
    
    y_pred_proba = model.predict_proba(X_val)[:, 1]
    
    try:
        auc = roc_auc_score(y_val, y_pred_proba)
        return auc
    except ValueError:
        return 0.0


def hyperparameter_tuning(X_train, y_train, X_val, y_val, n_trials=50):
    """Optunaë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
    if not OPTUNA_AVAILABLE:
        print("\nâš ï¸ Optunaê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        print("   ì„¤ì¹˜: pip install optuna")
        default_params = {
            'n_estimators': 200,
            'learning_rate': 0.05,
            'max_depth': 5,
            'min_child_samples': 20,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
            'class_weight': 'balanced',
            'random_state': 42,
            'verbosity': -1
        }
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµí•˜ì—¬ AUC ê³„ì‚°
        model = LGBMClassifier(**default_params)
        model.fit(X_train, y_train)
        y_pred_proba = model.predict_proba(X_val)[:, 1]
        try:
            auc = roc_auc_score(y_val, y_pred_proba)
        except ValueError:
            auc = 0.0
        
        return default_params, auc
    
    print(f"\nğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘ (Optuna, {n_trials} trials)")
    print("=" * 80)
    
    study = optuna.create_study(
        direction='maximize',
        study_name='risk_ai_hyperparameter_tuning'
    )
    
    study.optimize(
        lambda trial: objective(trial, X_train, y_train, X_val, y_val),
        n_trials=n_trials,
        show_progress_bar=True
    )
    
    print(f"\nâœ… ìµœì  íŒŒë¼ë¯¸í„°:")
    print(f"  AUC-ROC: {study.best_value:.4f}")
    print(f"\n  íŒŒë¼ë¯¸í„°:")
    for key, value in study.best_params.items():
        print(f"    {key}: {value}")
    
    return study.best_params, study.best_value


def main():
    print("ğŸ§  Project 3: Risk AI Model Training (with CV & Hyperparameter Tuning)")
    print("=" * 80)
    
    fe = FeatureEngineer()
    
    # 1. ë°ì´í„° ì¤€ë¹„
    print("\nğŸ“Š ë°ì´í„°ì…‹ ìƒì„± ë° ì „ì²˜ë¦¬ ì¤‘...")
    train_df, test_df, features = fe.prepare_ml_dataset()
    
    print(f"   - í•™ìŠµ ë°ì´í„°: {len(train_df)}ê±´")
    print(f"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê±´")
    print(f"   - ì‚¬ìš© íŠ¹ì„±: {features}")
    
    if len(train_df) < 100:
        print("âš ï¸ í•™ìŠµ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¤‘ë‹¨")
        return
    
    X_train = train_df[features]
    y_train = train_df['target_high_vol']
    
    X_test = test_df[features]
    y_test = test_df['target_high_vol']
    
    # 2. Time Series Cross-Validation
    cv_scores = time_series_cross_validation(X_train, y_train, n_splits=5)
    
    # 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Train ë°ì´í„°ë¥¼ ë‹¤ì‹œ Train/Valë¡œ ë¶„í• )
    print("\n" + "=" * 80)
    split_idx = int(len(X_train) * 0.8)
    X_train_tune = X_train.iloc[:split_idx]
    y_train_tune = y_train.iloc[:split_idx]
    X_val_tune = X_train.iloc[split_idx:]
    y_val_tune = y_train.iloc[split_idx:]
    
    best_params, best_auc = hyperparameter_tuning(
        X_train_tune, y_train_tune, X_val_tune, y_val_tune, n_trials=50
    )
    
    # 4. ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
    print("\n" + "=" * 80)
    print("ğŸ¤– ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...")
    
    final_model = LGBMClassifier(**best_params)
    final_model.fit(X_train, y_train)
    
    # 5. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€ ê²°ê³¼")
    print("=" * 80)
    
    y_pred = final_model.predict(X_test)
    y_pred_proba = final_model.predict_proba(X_test)[:, 1]
    
    try:
        test_auc = roc_auc_score(y_test, y_pred_proba)
        print(f"AUC-ROC: {test_auc:.4f}")
    except ValueError as e:
        print(f"âš ï¸ AUC-ROC ê³„ì‚° ë¶ˆê°€: {e}")
        test_auc = 0.0
    
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    
    # 6. íŠ¹ì„± ì¤‘ìš”ë„
    print("\nğŸ” íŠ¹ì„± ì¤‘ìš”ë„ (Top 5)")
    importance = pd.DataFrame({
        'feature': features,
        'importance': final_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(importance.head())
    
    # 7. ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    result_df = test_df.copy()
    result_df['pred_prob'] = y_pred_proba
    result_df['pred_label'] = y_pred
    
    output_path = ROOT / "data" / "project3_risk_pred_results_tuned.csv"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    result_df.to_csv(output_path, index=False)
    print(f"\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    # 8. ìš”ì•½ ë¦¬í¬íŠ¸
    print("\n" + "=" * 80)
    print("ğŸ“Š ìµœì¢… ìš”ì•½")
    print("=" * 80)
    print(f"Cross-Validation AUC-ROC: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})")
    print(f"Validation AUC-ROC (íŠœë‹): {best_auc:.4f}")
    print(f"Test AUC-ROC: {test_auc:.4f}")
    print(f"\nìµœì  íŒŒë¼ë¯¸í„°:")
    for key, value in best_params.items():
        print(f"  {key}: {value}")


if __name__ == "__main__":
    main()

