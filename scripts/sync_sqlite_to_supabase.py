#!/usr/bin/env python3
"""
SQLite project.db ë°ì´í„°ë¥¼ Supabaseë¡œ ì—…ë¡œë“œ
"""

import os
import sqlite3
from pathlib import Path
from dotenv import load_dotenv
from supabase import create_client
import time
import pandas as pd
from datetime import datetime

PROJECT_ROOT = Path(__file__).parent.parent
load_dotenv(PROJECT_ROOT / 'config' / '.env')

supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_ROLE_KEY')
)

DB_PATH = PROJECT_ROOT / 'data' / 'project.db'


def upload_table(table_name, column_mapping=None):
    """SQLite í…Œì´ë¸”ì„ Supabaseë¡œ ì—…ë¡œë“œ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“¤ {table_name} ì—…ë¡œë“œ")
    print("=" * 60)
    
    # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    try:
        # ë¹ˆ ì¿¼ë¦¬ë¡œ í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        supabase.table(table_name).select("*").limit(0).execute()
    except Exception as e:
        if 'not found' in str(e).lower() or 'schema cache' in str(e).lower():
            print(f"   âš ï¸ í…Œì´ë¸” '{table_name}'ì´ Supabaseì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"   â„¹ï¸ Supabase Dashboardì—ì„œ ë‹¤ìŒ SQLì„ ì‹¤í–‰í•˜ì„¸ìš”:")
            print(f"      sql/create_project_tables.sql íŒŒì¼ ì°¸ê³ ")
            return 0
        else:
            # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
            pass
    
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # ë°ì´í„° ì¡°íšŒ
    cursor.execute(f"SELECT * FROM {table_name}")
    rows = cursor.fetchall()
    
    if not rows:
        print(f"   âš ï¸ ë°ì´í„° ì—†ìŒ")
        conn.close()
        return 0
    
    print(f"   ì´ {len(rows):,}ê±´")
    
    # ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
    columns = [desc[0] for desc in cursor.description]
    
    # ë°°ì¹˜ ì—…ë¡œë“œ
    batch_size = 100
    uploaded = 0
    
    for i in range(0, len(rows), batch_size):
        batch = rows[i:i+batch_size]
        
        # dict ë³€í™˜ ë° ë°ì´í„° íƒ€ì… ì²˜ë¦¬
        data = []
        for row in batch:
            row_dict = dict(row)
            # ë°ì´í„° íƒ€ì… ë³€í™˜
            for k, v in row_dict.items():
                if v is None:
                    row_dict[k] = None
                elif isinstance(v, datetime):
                    # datetimeì„ ISO í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜
                    row_dict[k] = v.isoformat()
                elif isinstance(v, str) and k in ['date', 'created_at']:
                    # ë‚ ì§œ ë¬¸ìì—´ ì •ê·œí™” (UTC+0:00)
                    try:
                        dt = pd.to_datetime(v, utc=True)
                        row_dict[k] = dt.strftime('%Y-%m-%d') if k == 'date' else dt.isoformat()
                    except:
                        pass
                elif isinstance(v, (int, float)):
                    # NaN ì²˜ë¦¬
                    if pd.isna(v):
                        row_dict[k] = None
                    else:
                        row_dict[k] = v
            data.append(row_dict)
        
        try:
            # upsert ì‚¬ìš© (ì¤‘ë³µ ì‹œ ì—…ë°ì´íŠ¸)
            # on_conflict íŒŒë¼ë¯¸í„°ë¡œ unique constraint ì§€ì •
            # í…Œì´ë¸”ë³„ unique key ì¶”ì •
            if table_name in ['binance_futures_metrics', 'futures_extended_metrics']:
                # date, symbolì´ unique key
                result = supabase.table(table_name).upsert(data, on_conflict='date,symbol').execute()
            elif table_name in ['whale_daily_stats', 'whale_weekly_stats']:
                # date, coin_symbolì´ unique key
                result = supabase.table(table_name).upsert(data, on_conflict='date,coin_symbol').execute()
            elif table_name == 'bitinfocharts_whale_weekly':
                # coin, week_end_dateê°€ unique key
                result = supabase.table(table_name).upsert(data, on_conflict='coin,week_end_date').execute()
            elif 'date' in columns and 'symbol' in columns:
                result = supabase.table(table_name).upsert(data, on_conflict='date,symbol').execute()
            elif 'date' in columns:
                result = supabase.table(table_name).upsert(data, on_conflict='date').execute()
            else:
                result = supabase.table(table_name).upsert(data).execute()
            uploaded += len(batch)
        except Exception as e:
            error_msg = str(e)
            # ì¤‘ë³µ í‚¤ ì˜¤ë¥˜ëŠ” ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì´ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
            if 'duplicate' in error_msg.lower() or 'unique' in error_msg.lower():
                print(f"   â„¹ï¸ ë°°ì¹˜ {i//batch_size + 1}: ì¼ë¶€ ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬ (ê±´ë„ˆë›°ê¸°)")
                # ê°œë³„ upsert ì‹œë„ (ì¤‘ë³µì€ ë¬´ì‹œ)
                for row_dict in data:
                    try:
                        if table_name in ['binance_futures_metrics', 'futures_extended_metrics']:
                            supabase.table(table_name).upsert(row_dict, on_conflict='date,symbol').execute()
                        elif table_name in ['whale_daily_stats', 'whale_weekly_stats']:
                            supabase.table(table_name).upsert(row_dict, on_conflict='date,coin_symbol').execute()
                        elif table_name == 'bitinfocharts_whale_weekly':
                            supabase.table(table_name).upsert(row_dict, on_conflict='coin,week_end_date').execute()
                        elif 'date' in row_dict and 'symbol' in row_dict:
                            supabase.table(table_name).upsert(row_dict, on_conflict='date,symbol').execute()
                        elif 'date' in row_dict:
                            supabase.table(table_name).upsert(row_dict, on_conflict='date').execute()
                        else:
                            supabase.table(table_name).upsert(row_dict).execute()
                        uploaded += 1
                    except Exception as e2:
                        # ì¤‘ë³µì´ë©´ ê±´ë„ˆë›°ê¸°
                        if 'duplicate' not in str(e2).lower() and 'unique' not in str(e2).lower():
                            print(f"      âš ï¸ ê°œë³„ upsert ì˜¤ë¥˜: {str(e2)[:80]}")
            else:
                print(f"   âš ï¸ ë°°ì¹˜ {i//batch_size + 1} ì˜¤ë¥˜: {error_msg[:100]}")
                # ê°œë³„ upsert ì‹œë„
                for row_dict in data:
                    try:
                        if table_name in ['binance_futures_metrics', 'futures_extended_metrics']:
                            supabase.table(table_name).upsert(row_dict, on_conflict='date,symbol').execute()
                        elif table_name in ['whale_daily_stats', 'whale_weekly_stats']:
                            supabase.table(table_name).upsert(row_dict, on_conflict='date,coin_symbol').execute()
                        elif table_name == 'bitinfocharts_whale_weekly':
                            supabase.table(table_name).upsert(row_dict, on_conflict='coin,week_end_date').execute()
                        elif 'date' in row_dict and 'symbol' in row_dict:
                            supabase.table(table_name).upsert(row_dict, on_conflict='date,symbol').execute()
                        elif 'date' in row_dict:
                            supabase.table(table_name).upsert(row_dict, on_conflict='date').execute()
                        else:
                            supabase.table(table_name).upsert(row_dict).execute()
                        uploaded += 1
                    except Exception as e2:
                        if 'duplicate' not in str(e2).lower() and 'unique' not in str(e2).lower():
                            print(f"      âš ï¸ ê°œë³„ upsert ì˜¤ë¥˜: {str(e2)[:80]}")
        
        if (i // batch_size + 1) % 10 == 0:
            print(f"   ì§„í–‰: {uploaded:,}/{len(rows):,}ê±´")
        
        time.sleep(0.05)
    
    conn.close()
    print(f"   âœ… {uploaded:,}ê±´ ì—…ë¡œë“œ ì™„ë£Œ")
    return uploaded


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='SQLite â†’ Supabase ë°ì´í„° ë™ê¸°í™”')
    parser.add_argument('--table', type=str, help='íŠ¹ì • í…Œì´ë¸”ë§Œ ë™ê¸°í™” (ì˜ˆ: binance_futures_metrics)')
    parser.add_argument('--skip-existing', action='store_true', help='ê¸°ì¡´ ë°ì´í„° ê±´ë„ˆë›°ê¸° (í…ŒìŠ¤íŠ¸ìš©)')
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ“Š SQLite â†’ Supabase ë°ì´í„° ë™ê¸°í™”")
    print("=" * 80)
    
    # ëª¨ë“  í…Œì´ë¸” ëª©ë¡ (SQLiteì—ì„œ ìë™ ì¡°íšŒ)
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' ORDER BY name")
    all_tables = [row[0] for row in cursor.fetchall()]
    conn.close()
    
    print(f"\në°œê²¬ëœ í…Œì´ë¸”: {len(all_tables)}ê°œ")
    for table in all_tables:
        print(f"  - {table}")
    
    # ë™ê¸°í™”í•  í…Œì´ë¸” ëª©ë¡ ê²°ì •
    if args.table:
        if args.table in all_tables:
            tables_to_sync = [args.table]
            print(f"\nâœ… íŠ¹ì • í…Œì´ë¸”ë§Œ ë™ê¸°í™”: {args.table}")
        else:
            print(f"\nâŒ í…Œì´ë¸” '{args.table}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    else:
        # ë™ê¸°í™”í•  í…Œì´ë¸” ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)
        priority_tables = [
            'binance_futures_metrics',
            'futures_extended_metrics',
            'whale_daily_stats',
            'whale_weekly_stats',
            'binance_spot_daily',
            'binance_spot_weekly',
            'bybit_spot_daily',
            'bitget_spot_daily',
            'bitinfocharts_whale',
            'bitinfocharts_whale_weekly',
            'exchange_rate',
            'upbit_daily',
        ]
        
        # ìš°ì„ ìˆœìœ„ í…Œì´ë¸” + ë‚˜ë¨¸ì§€ í…Œì´ë¸”
        tables_to_sync = []
        for table in priority_tables:
            if table in all_tables:
                tables_to_sync.append(table)
        
        # ë‚˜ë¨¸ì§€ í…Œì´ë¸” ì¶”ê°€
        for table in all_tables:
            if table not in tables_to_sync:
                tables_to_sync.append(table)
        
        print(f"\në™ê¸°í™” ëŒ€ìƒ: {len(tables_to_sync)}ê°œ í…Œì´ë¸”")
    
    total_uploaded = 0
    
    for table in tables_to_sync:
        try:
            cnt = upload_table(table)
            total_uploaded += cnt
        except Exception as e:
            print(f"   âŒ {table} ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 80)
    print(f"ğŸ‰ ì´ {total_uploaded:,}ê±´ ì—…ë¡œë“œ ì™„ë£Œ")
    print("=" * 80)


if __name__ == "__main__":
    main()



