# 프로젝트 3 (Risk AI) 전문가 코드 리뷰 및 보완 계획

> **작성일**: 2025-11-23  
> **목적**: 프로젝트 3 (Risk AI)의 현재 상태 분석 및 전문가 관점에서의 개선 계획 수립

---

## 1. 프로젝트 3 목적 상기

### 핵심 목표
**BitInfoCharts 고래 지표와 바이낸스 선물 펀딩/OI 데이터를 결합하여 급격한 변동성 및 청산 리스크를 예측하는 AI 모델 구축**

### 핵심 가설
- 고래 집중도 변화가 시장 변동성의 선행 지표로 작용
- 펀딩비 이상 신호가 고변동성 예측에 유용
- OI(미결제약정) 급증이 청산 리스크 증가를 의미
- 여러 지표의 조합이 단일 지표보다 예측력이 높음

### 실용적 목적
- **투자자**: 고변동성 구간을 사전에 예측하여 리스크 관리
- **트레이더**: 청산 리스크가 높은 시점을 피하여 포지션 조정
- **연구자**: 고래 활동과 시장 변동성의 상관관계 분석

---

## 2. 현재 상태 분석

### 2.1 모델 학습 결과 (최신)

#### 성과 지표
- **AUC-ROC**: 0.6342 (약간의 예측 능력 있음, 하지만 낮은 수준)
- **정확도**: 58%
- **Precision (고변동성)**: 0.22
- **Recall (고변동성)**: 0.62
- **F1-Score (고변동성)**: 0.33

#### 특성 중요도
1. `whale_conc_change_7d`: 678 (가장 중요)
2. `avg_funding_rate`: 612
3. `funding_rate_zscore`: 557
4. `sum_open_interest`: 0 (문제!)
5. `long_position_pct`: 0 (문제!)
6. `oi_growth_7d`: 0 (문제!)
7. `volatility_ratio`: 0 (문제!)

#### 데이터 현황
- **학습 데이터**: 639건 (Train: 496건 정상, 143건 고변동성)
- **테스트 데이터**: 418건 (Test: 350건 정상, 68건 고변동성)
- **데이터 기간**: 2022-12-31 ~ 2025-11-22

---

## 3. 전문가 코드 리뷰

### 3.1 데이터 품질 문제 (Critical - 최우선 해결 필요)

#### 문제 1: `volatility_24h`가 모두 0.0
**원인 분석**:
- `fetch_futures_metrics.py`의 `build_daily_metrics()` 함수에서 하드코딩됨
- 코드 202-203줄: `volatility = 0.0`, `target_volatility = 0.0`
- 주석: "Need historical klines, but simple proxy is difficult without full history"

**영향**:
- 변동성 기반 타겟 변수 생성 불가
- `volatility_ratio` 특성이 모두 1.0으로 고정 (의미 없음)
- 모델이 변동성 정보를 전혀 학습하지 못함

**해결 방안**:
1. Binance Klines API를 사용하여 일봉 데이터 수집
2. `(high - low) / close` 또는 `priceChangePercent` 기반 변동성 계산
3. 또는 Binance 24hr Ticker API의 `priceChangePercent` 활용

#### 문제 2: `sum_open_interest`가 모두 0.0
**원인 분석**:
- Open Interest History API가 최근 30일만 제공
- 과거 데이터 수집 시 0.0으로 저장됨
- 일별 집계 로직은 있으나, 데이터 자체가 없음

**영향**:
- `oi_growth_7d` 특성이 모두 0.0 (의미 없음)
- OI 급증을 통한 청산 리스크 예측 불가

**해결 방안**:
1. 최근 30일 데이터라도 수집하여 활용
2. 또는 다른 데이터 소스(예: CryptoQuant, Glassnode) 활용 검토
3. OI 대신 다른 지표(예: 펀딩비, 롱/숏 비율)로 대체

#### 문제 3: `long_short_ratio`가 모두 0.0
**원인 분석**:
- 코드 197줄: `long_short_ratio = 0.0 # API limitation for historical`
- Binance API에서 과거 롱/숏 비율 데이터 제공 안 함

**영향**:
- `long_position_pct` 특성이 모두 0.5로 고정 (의미 없음)
- 롱/숏 비율 기반 리스크 분석 불가

**해결 방안**:
1. 최근 데이터만이라도 수집 (Binance Top Trader Long/Short Ratio API)
2. 또는 이 특성을 제거하고 다른 지표로 대체

### 3.2 타겟 변수 정의 문제

#### 현재 방법
- `volatility_24h`가 모두 0이므로, `avg_funding_rate` 변화율 기반으로 대체
- 상위 20% (quantile 0.8)를 고변동성으로 정의

#### 문제점
1. **Funding Rate 변화율 ≠ 변동성**: 펀딩비 변화와 실제 가격 변동성은 다른 개념
2. **상대적 기준의 한계**: 데이터 분포에 따라 threshold가 달라짐
3. **실용성 부족**: "상위 20%"라는 기준이 투자자에게 직관적이지 않음

#### 개선 방안
1. **절대 수치 기반 타겟 변수**: 
   - 실제 가격 변동성 5% 이상을 고변동성으로 정의
   - 또는 여러 지표 조합 (펀딩비 변화 + OI 변화 + 가격 변동)
2. **다중 타겟 변수**:
   - 고변동성 예측 (가격 변동성)
   - 청산 리스크 예측 (OI 급증 + 펀딩비 이상)
3. **임계값 조정 가능**: 설정 파일로 관리

### 3.3 Feature Engineering 문제

#### 문제 1: 특성 간 상관관계 미분석
- 7개 특성 중 4개가 0 또는 고정값
- 실제로 의미 있는 특성은 3개뿐 (`whale_conc_change_7d`, `avg_funding_rate`, `funding_rate_zscore`)
- 다중공선성 검토 없음

#### 문제 2: 특성 정규화/스케일링 부재
- 각 특성의 스케일이 다름 (펀딩비: 0.0001 수준, OI: 수십억)
- LightGBM은 트리 기반이라 스케일링이 필수는 아니지만, 일관성 있게 처리하는 것이 좋음

#### 문제 3: 시계열 특성 부족
- 현재: 7일 변화율, 30일 Z-Score만 사용
- 추가 가능: 이동평균, 추세 지표, 계절성 패턴

### 3.4 모델 학습 및 검증 문제

#### 문제 1: Cross-Validation 부재
- Train/Test Split만 수행
- Time Series 데이터인데 단일 Split만 사용
- 모델의 일반화 성능 검증 부족

#### 문제 2: 하이퍼파라미터 튜닝 부재
- 기본 파라미터만 사용 (`n_estimators=200`, `learning_rate=0.05`, `max_depth=5`)
- 최적 파라미터 탐색 없음

#### 문제 3: 모델 해석성 부족
- SHAP 값 계산 없음
- 특성 기여도 분석 부족
- 예측 결과 해석 어려움

#### 문제 4: 불균형 데이터 처리 부족
- 고변동성: 20% 미만 (Train: 22.4%, Test: 16.3%)
- `class_weight='balanced'`만으로는 부족할 수 있음
- SMOTE, 언더샘플링 등 추가 기법 검토 필요

### 3.5 평가 지표 문제

#### 문제 1: 평가 지표가 단순함
- Classification Report만 출력
- Precision-Recall Curve 없음
- Confusion Matrix 시각화 없음
- 예측 시점별 성과 분석 없음 (1일 후, 3일 후, 7일 후)

#### 문제 2: 비즈니스 지표 부재
- 실제 투자 결정에 필요한 지표 부족
- 예: "고변동성 예측 정확도가 60%일 때, 실제로 리스크를 피할 수 있는가?"
- False Positive/False Negative의 비용 분석 없음

### 3.6 코드 품질 문제

#### 문제 1: 에러 처리 부족
- API 호출 실패 시 재시도 로직 없음
- 데이터 검증 로직 부족
- 예외 상황 처리 미흡

#### 문제 2: 로깅 부족
- 상세한 로그 기록 없음
- 디버깅이 어려움
- 성과 지표 로깅 부족

#### 문제 3: 설정 파일 분리 부재
- 하드코딩된 값들이 많음 (예: split_date, threshold)
- 재현 가능성 저하

---

## 4. 보완 계획 (우선순위별)

### 우선순위 1: Critical - 데이터 품질 개선 (즉시 실행)

#### 4.1.1 `volatility_24h` 수집 로직 수정
**목표**: 실제 변동성 데이터 수집

**방법**:
1. Binance Klines API를 사용하여 일봉 데이터 수집
   - API: `GET /api/v3/klines` (현물) 또는 `/fapi/v1/klines` (선물)
   - 기간: 2023-01-01 ~ 현재
   - 계산: `(high - low) / close` 또는 `abs(close - open) / open`

2. 또는 Binance 24hr Ticker API 활용
   - API: `GET /fapi/v1/ticker/24hr`
   - `priceChangePercent` 필드 활용
   - 단점: 과거 데이터는 실시간 조회만 가능

**예상 소요 시간**: 4-6시간

#### 4.1.2 `sum_open_interest` 수집 로직 개선
**목표**: 최소한 최근 30일 데이터라도 활용

**방법**:
1. 최근 30일 데이터 수집 (API 제한 내에서)
2. 과거 데이터는 0.0으로 유지하되, 최근 데이터 활용
3. 또는 다른 데이터 소스 검토 (CryptoQuant, Glassnode)

**예상 소요 시간**: 2-3시간

#### 4.1.3 데이터 품질 검증 스크립트 강화
**목표**: 데이터 수집 후 자동 검증

**방법**:
- 각 컬럼의 NULL 비율, 0 값 비율 확인
- 이상치(Outlier) 검출
- 데이터 분포 시각화

**예상 소요 시간**: 2-3시간

---

### 우선순위 2: 타겟 변수 재정의 (단기)

#### 4.2.1 절대 수치 기반 타겟 변수 정의
**목표**: 실용적이고 직관적인 타겟 변수

**방법**:
1. **고변동성 정의**:
   - 가격 변동성 5% 이상 (절대 수치)
   - 또는 변동성 3% 이상 + 펀딩비 변화 0.1% 이상 (조합)

2. **청산 리스크 정의** (추가):
   - OI 급증 (7일 평균 대비 20% 이상)
   - 펀딩비 이상 (Z-Score > 2.0)
   - 고래 집중도 급변 (7일 변화율 > 10%)

3. **설정 파일로 관리**:
   ```yaml
   target_definition:
     high_volatility:
       price_change_threshold: 0.05  # 5%
       funding_rate_change_threshold: 0.001  # 0.1%
     liquidation_risk:
       oi_growth_threshold: 0.20  # 20%
       funding_zscore_threshold: 2.0
   ```

**예상 소요 시간**: 3-4시간

#### 4.2.2 타겟 변수 분포 분석
**목표**: 불균형 정도 측정 및 처리 방안 수립

**방법**:
- 고변동성 구간 비율 확인
- 시계열상 분포 확인 (특정 기간에 집중되어 있는지)
- 클래스 불균형 처리 방법 결정

**예상 소요 시간**: 1-2시간

---

### 우선순위 3: Feature Engineering 개선 (단기)

#### 4.3.1 특성 상관관계 분석
**목표**: 불필요한 특성 제거, 다중공선성 해결

**방법**:
1. 특성 간 상관관계 매트릭스 생성
2. VIF (Variance Inflation Factor) 계산
3. 상관관계가 높은 특성 제거 또는 결합

**예상 소요 시간**: 2-3시간

#### 4.3.2 추가 특성 생성
**목표**: 예측력 향상

**방법**:
1. **시계열 특성**:
   - 이동평균 (MA5, MA10, MA30)
   - 추세 지표 (RSI, MACD)
   - 계절성 패턴 (요일, 월별 패턴)

2. **상호작용 특성**:
   - 펀딩비 × OI
   - 고래 집중도 × 펀딩비
   - 펀딩비 Z-Score × OI 변화율

3. **지연 특성 (Lag Features)**:
   - 전일 펀딩비
   - 전일 OI
   - 전일 고래 집중도

**예상 소요 시간**: 4-6시간

#### 4.3.3 특성 선택 (Feature Selection)
**목표**: 최적 특성 조합 찾기

**방법**:
1. Recursive Feature Elimination (RFE)
2. 특성 중요도 기반 선택
3. 상호 검증을 통한 최적 조합 탐색

**예상 소요 시간**: 3-4시간

---

### 우선순위 4: 모델 개선 (중기)

#### 4.4.1 Time Series Cross-Validation
**목표**: 모델의 일반화 성능 검증

**방법**:
1. Time Series Split 적용 (5-fold)
2. 각 Fold별 성과 측정
3. 성과 분산 확인 (안정성 검증)

**예상 소요 시간**: 2-3시간

#### 4.4.2 하이퍼파라미터 튜닝
**목표**: 최적 모델 성능 달성

**방법**:
1. Optuna를 활용한 자동 튜닝
2. 주요 파라미터:
   - `n_estimators`: 100 ~ 500
   - `learning_rate`: 0.01 ~ 0.1
   - `max_depth`: 3 ~ 10
   - `min_child_samples`: 10 ~ 100
   - `subsample`: 0.6 ~ 1.0
   - `colsample_bytree`: 0.6 ~ 1.0

**예상 소요 시간**: 4-6시간

#### 4.4.3 불균형 데이터 처리
**목표**: 소수 클래스(고변동성) 예측 성능 향상

**방법**:
1. **SMOTE (Synthetic Minority Oversampling)**:
   - 소수 클래스 오버샘플링
   - 시계열 데이터이므로 주의 필요

2. **언더샘플링**:
   - 다수 클래스 언더샘플링
   - 데이터 손실 발생

3. **Focal Loss**:
   - 클래스 불균형에 특화된 손실 함수
   - LightGBM에서는 `focal_loss` 파라미터 없음 → 커스텀 손실 함수 필요

4. **앙상블 방법**:
   - 여러 모델의 가중 평균
   - 각 모델은 다른 클래스 가중치로 학습

**예상 소요 시간**: 6-8시간

#### 4.4.4 모델 해석성 향상 (SHAP)
**목표**: 예측 결과 해석 및 신뢰성 확보

**방법**:
1. SHAP 값 계산
2. 특성 기여도 시각화
3. 개별 예측 해석 리포트 생성

**예상 소요 시간**: 3-4시간

---

### 우선순위 5: 평가 지표 개선 (중기)

#### 4.5.1 상세 평가 지표 추가
**목표**: 모델 성능의 다각도 분석

**방법**:
1. **Precision-Recall Curve**:
   - 다양한 threshold에서의 성능 확인
   - 최적 threshold 선택

2. **Confusion Matrix 시각화**:
   - False Positive/False Negative 분석
   - 비즈니스 관점에서의 비용 분석

3. **예측 시점별 성과 분석**:
   - 1일 후 예측 정확도
   - 3일 후 예측 정확도
   - 7일 후 예측 정확도

**예상 소요 시간**: 3-4시간

#### 4.5.2 벤치마크 모델 비교
**목표**: 모델의 우수성 입증

**방법**:
1. **단순 규칙 기반 모델**:
   - 펀딩비 > 0.1% 시 고변동성 예측
   - OI 급증 시 고변동성 예측

2. **선형 모델**:
   - Logistic Regression
   - Ridge/Lasso Regression

3. **다른 트리 모델**:
   - Random Forest
   - XGBoost

**예상 소요 시간**: 4-6시간

---

### 우선순위 6: 코드 품질 개선 (중기)

#### 4.6.1 에러 처리 강화
**목표**: 안정적인 데이터 수집 및 모델 학습

**방법**:
1. API 호출 실패 시 재시도 로직 (Exponential Backoff)
2. 데이터 검증 로직 추가
3. 예외 상황 처리 및 로깅

**예상 소요 시간**: 3-4시간

#### 4.6.2 설정 파일 분리
**목표**: 재현 가능성 및 유지보수성 향상

**방법**:
1. `config/project3_config.yaml` 생성
2. 하드코딩된 값들을 설정 파일로 이동:
   - Train/Test Split 날짜
   - 타겟 변수 threshold
   - 모델 하이퍼파라미터
   - 특성 목록

**예상 소요 시간**: 2-3시간

#### 4.6.3 로깅 시스템 구축
**목표**: 디버깅 및 모니터링 용이

**방법**:
1. Python `logging` 모듈 활용
2. 로그 레벨 설정 (DEBUG, INFO, WARNING, ERROR)
3. 파일 로그 및 콘솔 로그 동시 출력
4. 성과 지표 자동 로깅

**예상 소요 시간**: 2-3시간

---

### 우선순위 7: 추가 분석 및 리포트 (장기)

#### 4.7.1 모델 성능 리포트 작성
**목표**: 결과 문서화 및 공유

**방법**:
1. 모델 성능 지표 정리
2. 특성 중요도 분석
3. 예측 오류 사례 분석
4. 개선 방안 제시

**예상 소요 시간**: 4-6시간

#### 4.7.2 실시간 예측 파이프라인 구축
**목표**: 실제 서비스 활용

**방법**:
1. 일일 자동 데이터 수집
2. 모델 재학습 (선택적)
3. 예측 결과 저장
4. 알림 시스템 (고변동성 예측 시)

**예상 소요 시간**: 8-12시간

---

## 5. 실행 우선순위 및 일정

### 즉시 실행 (Critical - 1주일 이내)
1. ✅ **데이터 변환 완료**: whale_transactions.csv → bitinfocharts_whale
2. ⏳ **volatility_24h 수집 로직 수정** (4-6시간)
3. ⏳ **sum_open_interest 수집 로직 개선** (2-3시간)
4. ⏳ **데이터 품질 검증 강화** (2-3시간)

**총 예상 시간**: 8-12시간

### 단기 (2주 이내)
5. ⏳ **타겟 변수 재정의** (3-4시간)
6. ⏳ **특성 상관관계 분석** (2-3시간)
7. ⏳ **추가 특성 생성** (4-6시간)
8. ⏳ **Time Series Cross-Validation** (2-3시간)

**총 예상 시간**: 11-16시간

### 중기 (3-4주 이내)
9. ⏳ **하이퍼파라미터 튜닝** (4-6시간)
10. ⏳ **불균형 데이터 처리** (6-8시간)
11. ⏳ **SHAP 분석** (3-4시간)
12. ⏳ **상세 평가 지표 추가** (3-4시간)
13. ⏳ **벤치마크 모델 비교** (4-6시간)

**총 예상 시간**: 20-28시간

### 장기 (1-2개월 이내)
14. ⏳ **코드 품질 개선** (7-10시간)
15. ⏳ **모델 성능 리포트 작성** (4-6시간)
16. ⏳ **실시간 예측 파이프라인 구축** (8-12시간)

**총 예상 시간**: 19-28시간

---

## 6. 예상 개선 효과

### 데이터 품질 개선 후
- **예상 AUC-ROC**: 0.70 ~ 0.80 (현재 0.63에서 향상)
- **의미 있는 특성**: 7개 → 7개 (현재 3개에서 향상)
- **타겟 변수 정확도**: 실제 변동성 기반으로 재정의

### 모델 개선 후
- **예상 AUC-ROC**: 0.75 ~ 0.85
- **Precision (고변동성)**: 0.40 ~ 0.60 (현재 0.22에서 향상)
- **Recall (고변동성)**: 0.60 ~ 0.80 (현재 0.62 유지 또는 향상)

### 실용성 향상
- 실제 투자 결정에 활용 가능한 수준의 예측 정확도
- 예측 결과 해석 가능 (SHAP 분석)
- 실시간 모니터링 가능

---

## 7. 리스크 및 제약사항

### 기술적 리스크
1. **API 제한**: Binance API의 Rate Limit 및 데이터 제공 제한
2. **데이터 소스 의존성**: 외부 API에 의존하므로 서비스 중단 시 영향
3. **모델 성능 한계**: 암호화폐 시장의 비효율성으로 인한 예측 한계

### 데이터 리스크
1. **데이터 품질**: 수집된 데이터의 정확성 검증 필요
2. **데이터 부족**: 특정 기간 데이터 부족 시 모델 성능 저하
3. **데이터 편향**: 특정 시장 상황에만 학습된 모델 가능성

### 비즈니스 리스크
1. **과적합**: 과거 데이터에만 최적화되어 미래 예측 실패 가능
2. **시장 변화**: 암호화폐 시장 특성 변화 시 모델 재학습 필요
3. **법적 리스크**: 투자 조언으로 오해받을 수 있음 (면책 조항 필요)

---

## 8. 다음 단계

### 즉시 실행할 작업
1. `volatility_24h` 수집 로직 수정 스크립트 작성
2. `sum_open_interest` 수집 로직 개선
3. 데이터 품질 검증 스크립트 실행

### 검토 필요 사항
1. 다른 데이터 소스 활용 가능성 (CryptoQuant, Glassnode 등)
2. 모델 아키텍처 변경 검토 (LSTM, Transformer 등 시계열 모델)
3. 실시간 서비스 구축 필요성

---

**작성자**: AI Assistant  
**검토 필요**: 머신러닝 전문가, 금융 데이터 분석 전문가, 암호화폐 시장 전문가

